{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import json\n",
    "from functools import partial\n",
    "from pathlib import Path\n",
    "\n",
    "import ipywidgets as widgets\n",
    "import torch\n",
    "from IPython.display import HTML, clear_output, display\n",
    "\n",
    "from delphi.config import ExperimentConfig, LatentConfig\n",
    "from delphi.latents import LatentDataset\n",
    "from delphi.latents.constructors import constructor\n",
    "from delphi.latents.samplers import sampler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_colorbar(min_value,\n",
    "                   max_value,\n",
    "                   white = 255,\n",
    "                   red_blue_ness = 250,\n",
    "                   positive_threshold = 0.01,\n",
    "                   negative_threshold = 0.01):\n",
    "    # Add color bar\n",
    "    colorbar = \"\"\n",
    "    num_colors = 4\n",
    "    if(min_value < -negative_threshold):\n",
    "        for i in range(num_colors, 0, -1):\n",
    "            ratio = i / (num_colors)\n",
    "            value = round((min_value*ratio),1)\n",
    "            text_color = \"255,255,255\" if ratio > 0.5 else \"0,0,0\"\n",
    "            colorbar += f'<span style=\"background-color:rgba(255, {int(red_blue_ness-(red_blue_ness*ratio))},{int(red_blue_ness-(red_blue_ness*ratio))},1); color:rgb({text_color})\">&nbsp{value}&nbsp</span>'  # noqa: E501\n",
    "    # Do zero\n",
    "    colorbar += f'<span style=\"background-color:rgba({white},{white},{white},1);color:rgb(0,0,0)\">&nbsp0.0&nbsp</span>' # noqa: E501\n",
    "    # Do positive\n",
    "    if(max_value > positive_threshold):\n",
    "        for i in range(1, num_colors+1):\n",
    "            ratio = i / (num_colors)\n",
    "            value = round((max_value*ratio),1)\n",
    "            text_color = \"255,255,255\" if ratio > 0.5 else \"0,0,0\"\n",
    "            colorbar += f'<span style=\"background-color:rgba({int(red_blue_ness-(red_blue_ness*ratio))},{int(red_blue_ness-(red_blue_ness*ratio))},255,1);color:rgb({text_color})\">&nbsp{value}&nbsp</span>'  # noqa: E501\n",
    "    return colorbar\n",
    "\n",
    "def value_to_color(activation,\n",
    "                    max_value,\n",
    "                      min_value,\n",
    "                        white = 255,\n",
    "                          red_blue_ness = 250, \n",
    "                          positive_threshold = 0.01,\n",
    "                            negative_threshold = 0.01):\n",
    "    if activation > positive_threshold:\n",
    "        ratio = activation/max_value\n",
    "        text_color = \"0,0,0\" if ratio <= 0.5 else \"255,255,255\"  \n",
    "        background_color = f'rgba({int(red_blue_ness-(red_blue_ness*ratio))},{int(red_blue_ness-(red_blue_ness*ratio))},255,1)'  # noqa: E501\n",
    "    elif activation < -negative_threshold:\n",
    "        ratio = activation/min_value\n",
    "        text_color = \"0,0,0\" if ratio <= 0.5 else \"255,255,255\"  \n",
    "        background_color = f'rgba(255, {int(red_blue_ness-(red_blue_ness*ratio))},{int(red_blue_ness-(red_blue_ness*ratio))},1)'  # noqa: E501\n",
    "    else:\n",
    "        text_color = \"0,0,0\"\n",
    "        background_color = f'rgba({white},{white},{white},1)'\n",
    "    return text_color, background_color\n",
    "\n",
    "def convert_token_array_to_list(array):\n",
    "    if isinstance(array, torch.Tensor):\n",
    "        if array.dim() == 1:\n",
    "            array = [array.tolist()]\n",
    "        elif array.dim()==2:\n",
    "            array = array.tolist()\n",
    "        else: \n",
    "            raise NotImplementedError(\"tokens must be 1 or 2 dimensional\")\n",
    "    elif isinstance(array, list):\n",
    "        # ensure it's a list of lists\n",
    "        if isinstance(array[0], int):\n",
    "            array = [array]\n",
    "    return array\n",
    "\n",
    "def escape(t):\n",
    "    t = t.replace(\" \", \"&nbsp;\").replace(\"<bos>\",\"BOS\").replace(\"<\", \"&lt;\").replace(\">\", \"&gt;\")\n",
    "    return t\n",
    "\n",
    "def tokens_and_activations_to_html(\n",
    "        toks,\n",
    "          activations,\n",
    "            tokenizer,\n",
    "              logit_diffs=None,\n",
    "                model_type=\"causal\"):\n",
    "    text_spacing = \"0.00em\"\n",
    "    toks = convert_token_array_to_list(toks)\n",
    "    activations = convert_token_array_to_list(activations)\n",
    "    inverse_vocab = {v: k for k, v in tokenizer.vocab.items()}\n",
    "    toks = [\n",
    "        [inverse_vocab[int(t)].replace('Ġ', ' ').replace(\"▁\", \" \").replace('\\n', '\\\\n') for t in tok]\n",
    "          for tok in toks]\n",
    "    print(len(activations))\n",
    "    print(len(toks))\n",
    "    highlighted_text = []\n",
    "    highlighted_text.append(\"\"\"\n",
    "<body style=\"background-color: black; color: white;\">\n",
    "\"\"\")\n",
    "    max_value = max([max(activ) for activ in activations])\n",
    "    min_value = min([min(activ) for activ in activations])\n",
    "    if(logit_diffs is not None and model_type != \"reward_model\"):\n",
    "        logit_max_value = max([max(activ) for activ in logit_diffs])\n",
    "        logit_min_value = min([min(activ) for activ in logit_diffs])\n",
    "\n",
    "    # Add color bar\n",
    "    highlighted_text.append(\"Token Activations: \" + make_colorbar(min_value, max_value))\n",
    "    if(logit_diffs is not None and model_type != \"reward_model\"):\n",
    "        highlighted_text.append('<div style=\"margin-top: 0.1em;\"></div>')\n",
    "        highlighted_text.append(\"Logit Diff: \" + make_colorbar(logit_min_value,\n",
    "                                                                logit_max_value))\n",
    "    \n",
    "    highlighted_text.append('<div style=\"margin-top: 0.5em;\"></div>')\n",
    "    for seq_ind, (act, tok) in enumerate(zip(activations, toks)):\n",
    "        for act_ind, (a, t) in enumerate(zip(act, tok)):\n",
    "            if(logit_diffs is not None and model_type != \"reward_model\"):\n",
    "                highlighted_text.append('<div style=\"display: inline-block;\">')\n",
    "            text_color, background_color = value_to_color(a, max_value, min_value)\n",
    "            highlighted_text.append(f'<span style=\"background-color:{background_color};margin-right: {text_spacing}; color:rgb({text_color})\">{escape(t)}</span>') # noqa: E501\n",
    "            if(logit_diffs is not None and model_type != \"reward_model\"):\n",
    "                logit_diffs_act = logit_diffs[seq_ind][act_ind]\n",
    "                _, logit_background_color = value_to_color(logit_diffs_act,\n",
    "                                                            logit_max_value,\n",
    "                                                              logit_min_value)\n",
    "                highlighted_text.append(f'<div style=\"display: block; margin-right: {text_spacing}; height: 10px; background-color:{logit_background_color}; text-align: center;\"></div></div>') # noqa: E501\n",
    "        if(logit_diffs is not None and model_type==\"reward_model\"):\n",
    "            reward_change = logit_diffs[seq_ind].item()\n",
    "            text_color, background_color = value_to_color(reward_change, 10, -10)\n",
    "            highlighted_text.append(f'<br><span>Reward: </span><span style=\"background-color:{background_color};margin-right: {text_spacing}; color:rgb({text_color})\">{reward_change:.2f}</span>')  # noqa: E501\n",
    "        highlighted_text.append('<div style=\"margin-top: 0.2em;\"></div>')\n",
    "    highlighted_text = ''.join(highlighted_text)\n",
    "    return highlighted_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def load_examples(raw_dir, hookpoint: str, features: list[int]):\n",
    "    latent_cfg = LatentConfig()\n",
    "\n",
    "    experiment_cfg = ExperimentConfig(n_non_activating=0)\n",
    "\n",
    "    # example_constructor = partial(\n",
    "    #     constructor,\n",
    "    #     n_not_active=experiment_cfg.n_non_activating,\n",
    "    #     ctx_len=experiment_cfg.example_ctx_len,\n",
    "    #     max_examples=latent_cfg.max_examples,\n",
    "    # )\n",
    "    # sampler = partial(sample, cfg=experiment_cfg)\n",
    "\n",
    "\n",
    "    dataset = LatentDataset(\n",
    "        raw_dir,\n",
    "        # cfg=latent_cfg,\n",
    "        latent_cfg, experiment_cfg,\n",
    "        modules=[hookpoint],\n",
    "        latents={hookpoint: torch.LongTensor(features)},\n",
    "        # constructor=example_constructor,\n",
    "        # sampler=sampler\n",
    "    )\n",
    "    \n",
    "    all_examples = {}\n",
    "    maximum_activations = {}\n",
    "    async for record in dataset:\n",
    "        train_examples = record.train\n",
    "        all_examples[str(record.latent)] = train_examples\n",
    "        maximum_activations[str(record.latent)] = record.max_activation\n",
    "\n",
    "    return all_examples, maximum_activations,dataset.tokenizer\n",
    "\n",
    "\n",
    "async def plot_examples( raw_dir, hookpoint: str, features: list[int]):\n",
    "    all_examples, maximum_acts,tokenizer = await load_examples(raw_dir, hookpoint, features)\n",
    "    keys = list(all_examples.keys())\n",
    "\n",
    "    current_index = [\n",
    "        0\n",
    "    ]  # Use a list to store the current index so it can be modified in the callback\n",
    "    explanations = {}  # Dictionary to store explanations\n",
    "\n",
    "    def display_example(index):\n",
    "        key = keys[index]\n",
    "        print(key)\n",
    "        list_tokens = []\n",
    "        list_activations = []\n",
    "        for example in all_examples[key]:\n",
    "            example_tokens = example.tokens\n",
    "            activations = example.activations / maximum_acts[key]\n",
    "            list_tokens.append(example_tokens)\n",
    "            list_activations.append(activations.tolist())\n",
    "\n",
    "        display(\n",
    "            HTML(\n",
    "                tokens_and_activations_to_html(\n",
    "                    list_tokens, list_activations, tokenizer\n",
    "                )\n",
    "            )\n",
    "        )\n",
    "\n",
    "    def on_submit(b):\n",
    "        key = keys[current_index[0]]\n",
    "        explanations[key] = text_box.value\n",
    "        current_index[0] = (current_index[0] + 1) % len(keys)\n",
    "        clear_output(wait=True)\n",
    "        display(widgets.HBox([text_box, submit_button, skip_button, save_button]))\n",
    "        display_example(current_index[0])\n",
    "\n",
    "    def on_skip(b):\n",
    "        current_index[0] = (current_index[0] + 1) % len(keys)\n",
    "        clear_output(wait=True)\n",
    "        display(widgets.HBox([text_box, submit_button, skip_button, save_button]))\n",
    "        display_example(current_index[0])\n",
    "\n",
    "    def on_save(b):\n",
    "        with open(f\"{hookpoint}_explanations.json\", \"w\") as f:\n",
    "            json.dump(explanations, f, indent=4)\n",
    "        print(f\"Explanations saved to {hookpoint}_explanations.json\")\n",
    "\n",
    "    text_box = widgets.Text(description=\"Explanation:\")\n",
    "    submit_button = widgets.Button(description=\"Submit\")\n",
    "    submit_button.on_click(on_submit)\n",
    "    skip_button = widgets.Button(description=\"Skip\")\n",
    "    skip_button.on_click(on_skip)\n",
    "    save_button = widgets.Button(description=\"Save\")\n",
    "    save_button.on_click(on_save)\n",
    "    display(widgets.HBox([text_box, submit_button, skip_button, save_button]))\n",
    "    display_example(current_index[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "raw_dir = Path(\"../results/monet_cache_converted/850m\")\n",
    "hookpoint = \".model.layers.16.router\"\n",
    "await plot_examples(raw_dir, hookpoint, [0, 4, 100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
